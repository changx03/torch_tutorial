{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision as tv\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "print(device)\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide fixed seed\n",
    "seed = 2**12\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path directory: ./dataset_root\n"
     ]
    }
   ],
   "source": [
    "root = os.path.join('.', 'dataset_root')\n",
    "print(f'Path directory: {root}')\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_normalize(data, xmax, xmin):\n",
    "    assert (type(data) == np.ndarray and \n",
    "        type(xmax) == np.ndarray and \n",
    "        type(xmin) == np.ndarray)\n",
    "    \n",
    "    assert data.shape[1] == len(xmax) and data.shape[1] == len(xmin)\n",
    "    \n",
    "    return (data - xmin) / (xmax - xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumeralDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        assert isinstance(data, torch.Tensor) \\\n",
    "            and isinstance(label, torch.Tensor)\n",
    "        \n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banknote Authentication\n",
    "\n",
    "- Input: 4\n",
    "- Output: {0, 1}\n",
    "- Classes: Binary classification. \n",
    "- Samples: 1372\n",
    "- 80:20 split \n",
    "- Train: 1098\n",
    "- Test: 274\n",
    "- Resacling to [0, 1]\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/banknote+authentication  \n",
    "https://www.kaggle.com/ritesaluja/bank-note-authentication-uci-data#BankNote_Authentication.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset_root/data_banknote_authentication.txt\n"
     ]
    }
   ],
   "source": [
    "banknote_dir = os.path.join(root, 'data_banknote_authentication.txt')\n",
    "print(banknote_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372, 5)\n",
      "1372 samples, 4 attributes\n",
      "Train: 1098, Test: 274\n",
      "(1098, 4) (274, 4)\n",
      "(1098,) (274,)\n"
     ]
    }
   ],
   "source": [
    "banknote_frame = pd.read_csv(\n",
    "    banknote_dir,\n",
    "    header=None,\n",
    "    names=['variance', 'skewness', 'curtosis', 'entropy', 'class'],\n",
    "    dtype=np.float32\n",
    ")\n",
    "print(banknote_frame.shape)\n",
    "n = len(banknote_frame.index)\n",
    "m = banknote_frame.shape[1] -1\n",
    "print(f'{n} samples, {m} attributes')\n",
    "shuffle_idx = np.random.permutation(n)\n",
    "assert len(shuffle_idx) == banknote_frame.shape[0]\n",
    "banknote_frame = banknote_frame.iloc[shuffle_idx]\n",
    "banknote_frame.head()\n",
    "\n",
    "# 80:20 split\n",
    "n_train = int(np.round(n * .8))\n",
    "n_test = n - n_train\n",
    "assert n_train + n_test == n\n",
    "print(f'Train: {n_train}, Test: {n_test}')\n",
    "\n",
    "# only apply scaling to [0, 1]\n",
    "banknote_data_train = banknote_frame.iloc[:n_train, :4].values\n",
    "x_max = np.max(banknote_data_train, axis=0)\n",
    "x_min = np.min(banknote_data_train, axis=0)\n",
    "banknote_data_train = scale_normalize(banknote_data_train, x_max, x_min)\n",
    "assert banknote_data_train.shape == (n_train, m)\n",
    "\n",
    "banknote_data_test = banknote_frame.iloc[-n_test:, :4].values\n",
    "banknote_data_test = scale_normalize(banknote_data_test, x_max, x_min)\n",
    "assert banknote_data_test.shape == (n_test, m)\n",
    "print(banknote_data_train.shape, banknote_data_test.shape)\n",
    "\n",
    "banknote_label_train = banknote_frame.iloc[:n_train, -1].values\n",
    "assert banknote_label_train.shape == (n_train,)\n",
    "banknote_label_test = banknote_frame.iloc[-n_test:, -1].values\n",
    "assert banknote_label_test.shape == (n_test,)\n",
    "print(banknote_label_train.shape, banknote_label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_banknote_train = NumeralDataset(\n",
    "    torch.Tensor(banknote_data_train), \n",
    "    torch.Tensor(banknote_label_train))\n",
    "dataset_banknote_test = NumeralDataset(\n",
    "    torch.Tensor(banknote_data_test), \n",
    "    torch.Tensor(banknote_label_test))\n",
    "\n",
    "dataloader_banknote_train = DataLoader(\n",
    "    dataset_banknote_train,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "dataloader_banknote_test = DataLoader(\n",
    "    dataset_banknote_test,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "# check batch size\n",
    "sample, label = next(iter(dataloader_banknote_train))\n",
    "assert sample.size() == (batch_size, m) and label.size() == (batch_size,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Iris  \n",
    "https://www.kaggle.com/uciml/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_frame = None\n",
    "iris_data_train = None\n",
    "iris_data_test = None\n",
    "iris_label_train = None\n",
    "iris_label_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iris_train = None\n",
    "dataset_iris_test = None\n",
    "dataloader_iris_train = None\n",
    "dataloader_iris_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Wisconsin (Diagnostic) Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)  \n",
    "https://www.kaggle.com/uciml/breast-cancer-wisconsin-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_frame = None\n",
    "bc_data_train = None\n",
    "bc_data_test = None\n",
    "bc_label_train = None\n",
    "bc_label_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bc_train = None\n",
    "dataset_bc_test = None\n",
    "dataloader_bc_train = None\n",
    "dataloader_bc_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeds of Wheat Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/seeds  \n",
    "https://www.kaggle.com/dongeorge/seed-from-uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_frame = None\n",
    "seed_data_train = None\n",
    "seed_data_test = None\n",
    "seed_label_train = None\n",
    "seed_label_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_seed_train = None\n",
    "dataset_seed_test = None\n",
    "dataloader_seed_train = None\n",
    "dataloader_seed_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTRU2 Data Set\n",
    "\n",
    "- PREDICTING A PULSAR STAR\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/HTRU2  \n",
    "https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "htru2_frame = None\n",
    "htru2_data_train = None\n",
    "htru2_data_test = None\n",
    "htru2_label_train = None\n",
    "htru2_label_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_htru2_train = None\n",
    "dataset_htru2_test = None\n",
    "dataloader_htru2_train = None\n",
    "dataloader_htru2_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
