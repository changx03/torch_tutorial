{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.9 (default, Nov  7 2019, 10:44:02) \n",
      "[GCC 8.3.0]\n",
      "/usr/lib/python36.zip\n",
      "/usr/lib/python3.6\n",
      "/usr/lib/python3.6/lib-dynload\n",
      "\n",
      "/home/lukec/venv/lib/python3.6/site-packages\n",
      "/home/lukec/Downloads/jax/build\n",
      "/home/lukec/.local/lib/python3.6/site-packages\n",
      "/usr/local/lib/python3.6/dist-packages\n",
      "/usr/lib/python3/dist-packages\n",
      "/home/lukec/venv/lib/python3.6/site-packages/IPython/extensions\n",
      "/home/lukec/.ipython\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(*sys.path, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for trained CNN\n",
    "root = os.path.join('.', 'dataset_root')\n",
    "# mean, std = [0.13066046], [0.30150425] # based on training set\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "momentum=0.9\n",
    "step_size=6\n",
    "gamma=0.1\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor_grid, mean=0., std=1., title=None):\n",
    "    assert isinstance(tensor_grid, torch.Tensor)\n",
    "    assert len(tensor_grid.size()) == 4, \\\n",
    "        f'For a batch of images only, {tensor_grid.size()} '\n",
    "    \n",
    "    tensor_grid = tv.utils.make_grid(tensor_grid)\n",
    "    grid = tensor_grid.numpy().transpose((1,2,0))\n",
    "    grid = std * grid + mean\n",
    "    grid = np.clip(grid, 0, 1)\n",
    "    plt.imshow(grid)\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "# foolbox model expects raw numpy array as image\n",
    "transform = tv.transforms.Compose([\n",
    "        tv.transforms.ToTensor(),\n",
    "#         tv.transforms.Normalize(mean, std)\n",
    "])\n",
    "train_dataset = tv.datasets.MNIST(\n",
    "    root,\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "test_dataset = tv.datasets.MNIST(\n",
    "    root,\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.fc1 = nn.Linear(5**2 * 64, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_linear, self).__init__()\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "                             \n",
    "    def forward(self, x):\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    corrects = 0\n",
    "        \n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # for display\n",
    "        total_loss += loss.item() * batch_size\n",
    "        preds = output.max(1, keepdim=True)[1]\n",
    "        corrects += preds.eq(y.view_as(preds)).sum().item()\n",
    "    \n",
    "    n = len(train_loader.dataset)\n",
    "    total_loss = total_loss / n\n",
    "    accuracy = corrects / n\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    corrects = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = x.size(0)\n",
    "            output = model(x)\n",
    "            loss = F.nll_loss(output, y)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            preds = output.max(1, keepdim=True)[1]\n",
    "            corrects += preds.eq(y.view_as(preds)).sum().item()\n",
    "    \n",
    "    n = len(test_loader.dataset)\n",
    "    total_loss = total_loss / n\n",
    "    accuracy = corrects / n\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Net1(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "    (fc1): Linear(in_features=1600, out_features=256, bias=True)\n",
      "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (1): Model_linear(\n",
      "    (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      "  (2): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# NOTE: NO GPU AT SCHOOL!\n",
    "model1 = Net1()\n",
    "model_linear = Model_linear()\n",
    "model_softmax = torch.nn.Sequential(\n",
    "    model1,\n",
    "    model_linear,\n",
    "    torch.nn.LogSoftmax(dim=1)\n",
    ")\n",
    "model_softmax.to(device)\n",
    "optimizer = torch.optim.SGD(model_softmax.parameters(), lr=lr, momentum=momentum)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, \n",
    "    step_size=step_size, \n",
    "    gamma=gamma)\n",
    "\n",
    "print(model_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1] 0m 2.2s Train Loss: 0.7668 Accuracy: 76.4517%, Test Loss: 0.1245 Accuracy: 95.9500%\n",
      "[ 2] 0m 2.0s Train Loss: 0.1258 Accuracy: 96.0767%, Test Loss: 0.0735 Accuracy: 97.6000%\n",
      "[ 3] 0m 2.1s Train Loss: 0.0844 Accuracy: 97.3783%, Test Loss: 0.0543 Accuracy: 98.1800%\n",
      "[ 4] 0m 2.1s Train Loss: 0.0650 Accuracy: 98.0100%, Test Loss: 0.0445 Accuracy: 98.4400%\n",
      "[ 5] 0m 2.4s Train Loss: 0.0533 Accuracy: 98.3517%, Test Loss: 0.0364 Accuracy: 98.7600%\n",
      "[ 6] 0m 2.0s Train Loss: 0.0459 Accuracy: 98.5283%, Test Loss: 0.0344 Accuracy: 98.8400%\n",
      "[ 7] 0m 2.1s Train Loss: 0.0327 Accuracy: 99.0067%, Test Loss: 0.0287 Accuracy: 98.9600%\n",
      "[ 8] 0m 2.0s Train Loss: 0.0306 Accuracy: 99.0750%, Test Loss: 0.0274 Accuracy: 99.0000%\n",
      "[ 9] 0m 2.1s Train Loss: 0.0302 Accuracy: 99.0733%, Test Loss: 0.0269 Accuracy: 99.0200%\n",
      "[10] 0m 2.0s Train Loss: 0.0296 Accuracy: 99.0900%, Test Loss: 0.0266 Accuracy: 99.0300%\n",
      "[11] 0m 2.1s Train Loss: 0.0281 Accuracy: 99.1450%, Test Loss: 0.0266 Accuracy: 99.0300%\n",
      "[12] 0m 2.0s Train Loss: 0.0276 Accuracy: 99.1567%, Test Loss: 0.0261 Accuracy: 99.0100%\n",
      "[13] 0m 2.1s Train Loss: 0.0266 Accuracy: 99.1617%, Test Loss: 0.0259 Accuracy: 99.0300%\n",
      "[14] 0m 2.0s Train Loss: 0.0266 Accuracy: 99.1833%, Test Loss: 0.0257 Accuracy: 99.0700%\n",
      "[15] 0m 2.1s Train Loss: 0.0263 Accuracy: 99.1967%, Test Loss: 0.0257 Accuracy: 99.0700%\n",
      "[16] 0m 2.1s Train Loss: 0.0266 Accuracy: 99.1817%, Test Loss: 0.0257 Accuracy: 99.0700%\n",
      "[17] 0m 2.1s Train Loss: 0.0267 Accuracy: 99.1750%, Test Loss: 0.0257 Accuracy: 99.0500%\n",
      "[18] 0m 2.1s Train Loss: 0.0265 Accuracy: 99.2100%, Test Loss: 0.0257 Accuracy: 99.0700%\n",
      "[19] 0m 2.1s Train Loss: 0.0265 Accuracy: 99.2117%, Test Loss: 0.0257 Accuracy: 99.0700%\n",
      "[20] 0m 2.1s Train Loss: 0.0260 Accuracy: 99.2217%, Test Loss: 0.0256 Accuracy: 99.0700%\n",
      "[21] 0m 2.0s Train Loss: 0.0261 Accuracy: 99.2183%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[22] 0m 2.1s Train Loss: 0.0264 Accuracy: 99.1867%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[23] 0m 2.0s Train Loss: 0.0259 Accuracy: 99.2450%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[24] 0m 2.1s Train Loss: 0.0257 Accuracy: 99.2000%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[25] 0m 2.0s Train Loss: 0.0260 Accuracy: 99.2017%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[26] 0m 2.1s Train Loss: 0.0259 Accuracy: 99.2050%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[27] 0m 2.0s Train Loss: 0.0261 Accuracy: 99.2033%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[28] 0m 2.1s Train Loss: 0.0257 Accuracy: 99.2283%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[29] 0m 2.0s Train Loss: 0.0256 Accuracy: 99.2250%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[30] 0m 2.1s Train Loss: 0.0258 Accuracy: 99.2367%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[31] 0m 2.1s Train Loss: 0.0251 Accuracy: 99.2367%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[32] 0m 2.1s Train Loss: 0.0259 Accuracy: 99.1867%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[33] 0m 2.0s Train Loss: 0.0261 Accuracy: 99.2400%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[34] 0m 2.1s Train Loss: 0.0258 Accuracy: 99.2350%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[35] 0m 2.1s Train Loss: 0.0253 Accuracy: 99.2583%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[36] 0m 2.3s Train Loss: 0.0266 Accuracy: 99.2233%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[37] 0m 2.2s Train Loss: 0.0265 Accuracy: 99.1933%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[38] 0m 2.1s Train Loss: 0.0258 Accuracy: 99.2150%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[39] 0m 2.1s Train Loss: 0.0257 Accuracy: 99.2067%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "[40] 0m 2.1s Train Loss: 0.0258 Accuracy: 99.2483%, Test Loss: 0.0256 Accuracy: 99.0800%\n",
      "Training completed in 1m 23.6s\n",
      "Best val Acc: 0.990800\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    best_model_state = copy.deepcopy(model_softmax.state_dict())\n",
    "    best_tr_acc = 0.0\n",
    "    best_va_acc = 0.0\n",
    "    prev_loss = 1e10\n",
    "    \n",
    "    tr_loss, tr_acc = train(model_softmax, train_loader, optimizer)\n",
    "    va_loss, va_acc = validate(model_softmax, test_loader)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # save best result\n",
    "    if tr_acc >= best_tr_acc and va_acc >= best_va_acc:\n",
    "        best_model_state = copy.deepcopy(model_softmax.state_dict())\n",
    "        best_tr_acc = tr_acc\n",
    "        best_va_acc = va_acc\n",
    "    \n",
    "    # display\n",
    "    time_elapsed = time.time() - start\n",
    "    print(('[{:2d}] {:.0f}m {:.1f}s Train Loss: {:.4f} Accuracy: {:.4f}%, ' +\n",
    "        'Test Loss: {:.4f} Accuracy: {:.4f}%').format(\n",
    "            epoch+1, time_elapsed // 60, time_elapsed % 60,\n",
    "            tr_loss, tr_acc*100.,\n",
    "            va_loss, va_acc*100.))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {:.0f}m {:.1f}s'.format(\n",
    "    time_elapsed // 60,\n",
    "    time_elapsed % 60))\n",
    "print(f'Best val Acc: {best_va_acc:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_softmax.state_dict(), 'mnist_model3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
