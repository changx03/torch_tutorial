{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(*sys.path, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "num_workers = os.cpu_count()\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for trained CNN\n",
    "root = os.path.join('.', 'dataset_root')\n",
    "# mean, std = [0.13066046], [0.30150425] # based on training set\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "momentum=0.9\n",
    "step_size=6\n",
    "gamma=0.1\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor_grid, mean=0., std=1., title=None):\n",
    "    assert isinstance(tensor_grid, torch.Tensor)\n",
    "    assert len(tensor_grid.size()) == 4, \\\n",
    "        f'For a batch of images only, {tensor_grid.size()} '\n",
    "    \n",
    "    tensor_grid = tv.utils.make_grid(tensor_grid)\n",
    "    grid = tensor_grid.numpy().transpose((1,2,0))\n",
    "    grid = std * grid + mean\n",
    "    grid = np.clip(grid, 0, 1)\n",
    "    plt.imshow(grid)\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "# foolbox model expects raw numpy array as image\n",
    "transform = tv.transforms.Compose([\n",
    "        tv.transforms.ToTensor(),\n",
    "#         tv.transforms.Normalize(mean, std)\n",
    "])\n",
    "train_dataset = tv.datasets.MNIST(\n",
    "    root,\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "test_dataset = tv.datasets.MNIST(\n",
    "    root,\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.dropout = nn.Dropout2d(0.2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(800, 128)\n",
    "        self.fc2 = nn.Linear(128, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "                             \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc2 = nn.Linear(128, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "                             \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    corrects = 0\n",
    "        \n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # for display\n",
    "        total_loss += loss.item() * batch_size\n",
    "        preds = output.max(1, keepdim=True)[1]\n",
    "        corrects += preds.eq(y.view_as(preds)).sum().item()\n",
    "    \n",
    "    n = len(train_loader.dataset)\n",
    "    total_loss = total_loss / n\n",
    "    accuracy = corrects / n\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    corrects = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = x.size(0)\n",
    "            output = model(x)\n",
    "            loss = F.nll_loss(output, y)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            preds = output.max(1, keepdim=True)[1]\n",
    "            corrects += preds.eq(y.view_as(preds)).sum().item()\n",
    "    \n",
    "    n = len(test_loader.dataset)\n",
    "    total_loss = total_loss / n\n",
    "    accuracy = corrects / n\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: NO GPU AT SCHOOL!\n",
    "model1 = Net1()\n",
    "model2 = Net2()\n",
    "model_softmax = torch.nn.Sequential(\n",
    "    model1,\n",
    "    model2,\n",
    "    torch.nn.LogSoftmax(dim=1)\n",
    ")\n",
    "model_softmax.to(device)\n",
    "optimizer = torch.optim.SGD(model_softmax.parameters(), lr=lr, momentum=momentum)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, \n",
    "    step_size=step_size, \n",
    "    gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1] 0m 1.8s Train Loss: 0.1634 Accuracy: 94.9983%, Test Loss: 0.0839 Accuracy: 97.3000%\n",
      "[ 2] 0m 1.7s Train Loss: 0.1004 Accuracy: 96.8533%, Test Loss: 0.0596 Accuracy: 98.0900%\n",
      "[ 3] 0m 1.8s Train Loss: 0.0764 Accuracy: 97.6200%, Test Loss: 0.0636 Accuracy: 97.9600%\n",
      "[ 4] 0m 1.7s Train Loss: 0.0658 Accuracy: 97.9450%, Test Loss: 0.0434 Accuracy: 98.4400%\n",
      "[ 5] 0m 1.7s Train Loss: 0.0557 Accuracy: 98.2983%, Test Loss: 0.0403 Accuracy: 98.6200%\n",
      "[ 6] 0m 1.8s Train Loss: 0.0413 Accuracy: 98.7300%, Test Loss: 0.0342 Accuracy: 98.8500%\n",
      "[ 7] 0m 1.7s Train Loss: 0.0382 Accuracy: 98.7917%, Test Loss: 0.0337 Accuracy: 98.8600%\n",
      "[ 8] 0m 1.7s Train Loss: 0.0373 Accuracy: 98.8233%, Test Loss: 0.0330 Accuracy: 98.8700%\n",
      "[ 9] 0m 1.7s Train Loss: 0.0363 Accuracy: 98.8717%, Test Loss: 0.0325 Accuracy: 98.9500%\n",
      "[10] 0m 1.7s Train Loss: 0.0364 Accuracy: 98.8800%, Test Loss: 0.0335 Accuracy: 98.8300%\n",
      "[11] 0m 1.7s Train Loss: 0.0350 Accuracy: 98.9333%, Test Loss: 0.0334 Accuracy: 98.8400%\n",
      "[12] 0m 1.7s Train Loss: 0.0344 Accuracy: 98.9517%, Test Loss: 0.0322 Accuracy: 98.9000%\n",
      "[13] 0m 1.7s Train Loss: 0.0337 Accuracy: 98.9767%, Test Loss: 0.0320 Accuracy: 98.8900%\n",
      "[14] 0m 1.7s Train Loss: 0.0346 Accuracy: 98.9467%, Test Loss: 0.0321 Accuracy: 98.8900%\n",
      "[15] 0m 1.8s Train Loss: 0.0343 Accuracy: 98.9217%, Test Loss: 0.0321 Accuracy: 98.9100%\n",
      "[16] 0m 1.7s Train Loss: 0.0332 Accuracy: 98.9367%, Test Loss: 0.0320 Accuracy: 98.8900%\n",
      "[17] 0m 1.7s Train Loss: 0.0335 Accuracy: 98.9717%, Test Loss: 0.0318 Accuracy: 98.8900%\n",
      "[18] 0m 1.7s Train Loss: 0.0330 Accuracy: 98.9800%, Test Loss: 0.0318 Accuracy: 98.8900%\n",
      "[19] 0m 1.8s Train Loss: 0.0333 Accuracy: 98.9733%, Test Loss: 0.0318 Accuracy: 98.8900%\n",
      "[20] 0m 1.7s Train Loss: 0.0336 Accuracy: 98.9500%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[21] 0m 1.7s Train Loss: 0.0344 Accuracy: 98.9250%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[22] 0m 1.7s Train Loss: 0.0337 Accuracy: 98.9583%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[23] 0m 1.7s Train Loss: 0.0329 Accuracy: 98.9900%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[24] 0m 1.8s Train Loss: 0.0339 Accuracy: 98.9633%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[25] 0m 1.8s Train Loss: 0.0336 Accuracy: 98.9817%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[26] 0m 1.7s Train Loss: 0.0328 Accuracy: 99.0233%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[27] 0m 1.8s Train Loss: 0.0335 Accuracy: 98.9417%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[28] 0m 1.7s Train Loss: 0.0329 Accuracy: 98.9917%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[29] 0m 1.7s Train Loss: 0.0331 Accuracy: 98.9967%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[30] 0m 1.9s Train Loss: 0.0338 Accuracy: 98.9617%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[31] 0m 1.8s Train Loss: 0.0333 Accuracy: 98.9867%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[32] 0m 1.8s Train Loss: 0.0337 Accuracy: 98.9767%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[33] 0m 1.7s Train Loss: 0.0322 Accuracy: 99.0167%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[34] 0m 1.8s Train Loss: 0.0332 Accuracy: 98.9750%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[35] 0m 1.7s Train Loss: 0.0333 Accuracy: 98.9733%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[36] 0m 1.7s Train Loss: 0.0330 Accuracy: 98.9700%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[37] 0m 1.7s Train Loss: 0.0325 Accuracy: 98.9950%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[38] 0m 1.7s Train Loss: 0.0327 Accuracy: 98.9983%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[39] 0m 1.7s Train Loss: 0.0333 Accuracy: 98.9333%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "[40] 0m 1.7s Train Loss: 0.0335 Accuracy: 98.9533%, Test Loss: 0.0319 Accuracy: 98.8800%\n",
      "Training completed in 1m 10.1s\n",
      "Best val Acc: 0.988800\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    best_model_state = copy.deepcopy(model_softmax.state_dict())\n",
    "    best_tr_acc = 0.0\n",
    "    best_va_acc = 0.0\n",
    "    prev_loss = 1e10\n",
    "    \n",
    "    tr_loss, tr_acc = train(model_softmax, train_loader, optimizer)\n",
    "    va_loss, va_acc = validate(model_softmax, test_loader)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # save best result\n",
    "    if tr_acc >= best_tr_acc and va_acc >= best_va_acc:\n",
    "        best_model_state = copy.deepcopy(model_softmax.state_dict())\n",
    "        best_tr_acc = tr_acc\n",
    "        best_va_acc = va_acc\n",
    "    \n",
    "    # display\n",
    "    time_elapsed = time.time() - start\n",
    "    print(('[{:2d}] {:.0f}m {:.1f}s Train Loss: {:.4f} Accuracy: {:.4f}%, ' +\n",
    "        'Test Loss: {:.4f} Accuracy: {:.4f}%').format(\n",
    "            epoch+1, time_elapsed // 60, time_elapsed % 60,\n",
    "            tr_loss, tr_acc*100.,\n",
    "            va_loss, va_acc*100.))\n",
    "    \n",
    "time_elapsed = time.time() - since\n",
    "print('Training completed in {:.0f}m {:.1f}s'.format(\n",
    "    time_elapsed // 60,\n",
    "    time_elapsed % 60))\n",
    "print(f'Best val Acc: {best_va_acc:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_softmax.state_dict(), 'mnist_model3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
