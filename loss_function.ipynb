{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for PyTorch Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from a CSV file using Pandas\n",
    "Download link: https://archive.ics.uci.edu/ml/datasets/Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth        class\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from CSV file\n",
    "file_path = os.path.join('data', 'iris.data')\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    header=None,\n",
    "    names=['SepalLength', 'SepalWidth',\n",
    "           'PetalLength', 'PetalWidth', 'class'],\n",
    "    dtype={'SepalLength': np.float32,\n",
    "           'SepalWidth': np.float32,\n",
    "           'PetalLength': np.float32,\n",
    "           'PetalWidth': np.float32,\n",
    "           'class': np.str},\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Categorical Attribute into Integer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Iris-setosa\n",
       "1         Iris-setosa\n",
       "2         Iris-setosa\n",
       "3         Iris-setosa\n",
       "4         Iris-setosa\n",
       "            ...      \n",
       "145    Iris-virginica\n",
       "146    Iris-virginica\n",
       "147    Iris-virginica\n",
       "148    Iris-virginica\n",
       "149    Iris-virginica\n",
       "Name: class, Length: 150, dtype: category\n",
       "Categories (3, object): [Iris-setosa, Iris-versicolor, Iris-virginica]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  class\n",
       "0          5.1         3.5          1.4         0.2      0\n",
       "1          4.9         3.0          1.4         0.2      0\n",
       "2          4.7         3.2          1.3         0.2      0\n",
       "3          4.6         3.1          1.5         0.2      0\n",
       "4          5.0         3.6          1.4         0.2      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = df['class'].astype('category')\n",
    "df['class'] = df['class'].cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Train Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLength  SepalWidth  PetalLength  PetalWidth  class\n",
       "71          6.1         2.8          4.0         1.3      1\n",
       "60          5.0         2.0          3.5         1.0      1\n",
       "96          5.7         2.9          4.2         1.3      1\n",
       "9           4.9         3.1          1.5         0.1      0\n",
       "51          6.4         3.2          4.5         1.5      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle data\n",
    "n = len(df.index)\n",
    "shuffled_indices = np.random.permutation(n)\n",
    "df = df.iloc[shuffled_indices]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4) (90,)\n",
      "(60, 4) (60,)\n",
      "float32 float32\n"
     ]
    }
   ],
   "source": [
    "# Split train/test sets\n",
    "n = len(df.index)\n",
    "num_train = int(n * 0.6)\n",
    "num_test = n - num_train\n",
    "x_train = df.iloc[:num_train, :4].values\n",
    "y_train = df.iloc[:num_train, -1].values.astype(np.long)\n",
    "x_test = df.iloc[-num_test:, :4].values\n",
    "y_test = df.iloc[-num_test:, -1].values.astype(np.long)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(x_train.dtype, x_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Numpy Array to PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpDataset(Dataset):\n",
    "    \"\"\"Convert Numpy array into PyTorch Dataset\"\"\"\n",
    "    def __init__(self, data, label):\n",
    "        self.data = torch.from_numpy(data)\n",
    "        self.label = torch.from_numpy(label)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 4]) torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "# Prepare DataLoader for PyTorch\n",
    "train_dataset = NpDataset(x_train, y_train)\n",
    "test_dataset = NpDataset(x_test, y_test)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    ")\n",
    "x, y = next(iter(test_dataloader))\n",
    "print(x.size(), y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisNN, self).__init__()\n",
    "        self.fn1 = nn.Linear(4, 6)\n",
    "        self.fn2 = nn.Linear(6, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fn1(x))\n",
    "        x = self.fn2(x)\n",
    "#         x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "        \n",
    "model = IrisNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1231, -1.0510,  1.0529],\n",
       "        [ 0.2989, -1.3437,  1.1933]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model(x[:2])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IrisNN(\n",
       "  (fn1): Linear(in_features=4, out_features=6, bias=True)\n",
       "  (fn2): Linear(in_features=6, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.NLLLoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation for Updating the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        n = x.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        score = model(x)\n",
    "        loss = loss_fn(score, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predictions = score.max(1, keepdim=True)[1]\n",
    "        num_correct = predictions.eq(y.view_as(predictions)).sum().item()\n",
    "    \n",
    "    acc = num_correct / n\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Forward for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            n = x.size(0)\n",
    "            \n",
    "            score = model(x)\n",
    "            loss = loss_fn(score, y)\n",
    "            predictions = score.max(1, keepdim=True)[1]\n",
    "            num_correct = predictions.eq(y.view_as(predictions)).sum().item()\n",
    "    \n",
    "    acc = num_correct / n\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100] Train loss: 1.5639 acc: 26.67 - Test loss: 1.2292 acc: 43.33\n",
      "[1/100] Train loss: 1.4761 acc: 26.67 - Test loss: 1.1796 acc: 43.33\n",
      "[2/100] Train loss: 1.3510 acc: 26.67 - Test loss: 1.1676 acc: 18.33\n",
      "[3/100] Train loss: 1.2470 acc: 8.89 - Test loss: 1.2118 acc: 5.00\n",
      "[4/100] Train loss: 1.1975 acc: 4.44 - Test loss: 1.2992 acc: 26.67\n",
      "[5/100] Train loss: 1.2015 acc: 37.78 - Test loss: 1.3967 acc: 26.67\n",
      "[6/100] Train loss: 1.2342 acc: 37.78 - Test loss: 1.4681 acc: 26.67\n",
      "[7/100] Train loss: 1.2642 acc: 37.78 - Test loss: 1.4903 acc: 26.67\n",
      "[8/100] Train loss: 1.2701 acc: 37.78 - Test loss: 1.4599 acc: 26.67\n",
      "[9/100] Train loss: 1.2468 acc: 37.78 - Test loss: 1.3903 acc: 26.67\n",
      "[10/100] Train loss: 1.2032 acc: 37.78 - Test loss: 1.3021 acc: 26.67\n",
      "[11/100] Train loss: 1.1540 acc: 37.78 - Test loss: 1.2145 acc: 26.67\n",
      "[12/100] Train loss: 1.1122 acc: 37.78 - Test loss: 1.1400 acc: 23.33\n",
      "[13/100] Train loss: 1.0846 acc: 37.78 - Test loss: 1.0837 acc: 11.67\n",
      "[14/100] Train loss: 1.0716 acc: 12.22 - Test loss: 1.0447 acc: 68.33\n",
      "[15/100] Train loss: 1.0691 acc: 57.78 - Test loss: 1.0192 acc: 73.33\n",
      "[16/100] Train loss: 1.0712 acc: 62.22 - Test loss: 1.0025 acc: 71.67\n",
      "[17/100] Train loss: 1.0718 acc: 61.11 - Test loss: 0.9905 acc: 70.00\n",
      "[18/100] Train loss: 1.0673 acc: 60.00 - Test loss: 0.9815 acc: 71.67\n",
      "[19/100] Train loss: 1.0563 acc: 61.11 - Test loss: 0.9751 acc: 73.33\n",
      "[20/100] Train loss: 1.0401 acc: 62.22 - Test loss: 0.9723 acc: 73.33\n",
      "[21/100] Train loss: 1.0215 acc: 62.22 - Test loss: 0.9735 acc: 73.33\n",
      "[22/100] Train loss: 1.0032 acc: 62.22 - Test loss: 0.9786 acc: 88.33\n",
      "[23/100] Train loss: 0.9872 acc: 80.00 - Test loss: 0.9862 acc: 85.00\n",
      "[24/100] Train loss: 0.9742 acc: 94.44 - Test loss: 0.9940 acc: 56.67\n",
      "[25/100] Train loss: 0.9633 acc: 78.89 - Test loss: 0.9992 acc: 55.00\n",
      "[26/100] Train loss: 0.9534 acc: 71.11 - Test loss: 0.9993 acc: 55.00\n",
      "[27/100] Train loss: 0.9428 acc: 71.11 - Test loss: 0.9927 acc: 55.00\n",
      "[28/100] Train loss: 0.9304 acc: 70.00 - Test loss: 0.9786 acc: 55.00\n",
      "[29/100] Train loss: 0.9155 acc: 71.11 - Test loss: 0.9574 acc: 55.00\n",
      "[30/100] Train loss: 0.8980 acc: 72.22 - Test loss: 0.9304 acc: 56.67\n",
      "[31/100] Train loss: 0.8785 acc: 72.22 - Test loss: 0.8996 acc: 56.67\n",
      "[32/100] Train loss: 0.8579 acc: 75.56 - Test loss: 0.8669 acc: 63.33\n",
      "[33/100] Train loss: 0.8368 acc: 81.11 - Test loss: 0.8343 acc: 78.33\n",
      "[34/100] Train loss: 0.8158 acc: 92.22 - Test loss: 0.8031 acc: 93.33\n",
      "[35/100] Train loss: 0.7951 acc: 97.78 - Test loss: 0.7740 acc: 96.67\n",
      "[36/100] Train loss: 0.7742 acc: 97.78 - Test loss: 0.7472 acc: 91.67\n",
      "[37/100] Train loss: 0.7528 acc: 93.33 - Test loss: 0.7227 acc: 88.33\n",
      "[38/100] Train loss: 0.7305 acc: 91.11 - Test loss: 0.7006 acc: 88.33\n",
      "[39/100] Train loss: 0.7075 acc: 91.11 - Test loss: 0.6809 acc: 88.33\n",
      "[40/100] Train loss: 0.6843 acc: 91.11 - Test loss: 0.6637 acc: 91.67\n",
      "[41/100] Train loss: 0.6616 acc: 93.33 - Test loss: 0.6485 acc: 95.00\n",
      "[42/100] Train loss: 0.6398 acc: 96.67 - Test loss: 0.6347 acc: 96.67\n",
      "[43/100] Train loss: 0.6192 acc: 97.78 - Test loss: 0.6212 acc: 95.00\n",
      "[44/100] Train loss: 0.5995 acc: 98.89 - Test loss: 0.6072 acc: 96.67\n",
      "[45/100] Train loss: 0.5804 acc: 97.78 - Test loss: 0.5923 acc: 93.33\n",
      "[46/100] Train loss: 0.5616 acc: 97.78 - Test loss: 0.5766 acc: 93.33\n",
      "[47/100] Train loss: 0.5433 acc: 97.78 - Test loss: 0.5607 acc: 93.33\n",
      "[48/100] Train loss: 0.5257 acc: 97.78 - Test loss: 0.5453 acc: 93.33\n",
      "[49/100] Train loss: 0.5093 acc: 97.78 - Test loss: 0.5310 acc: 93.33\n",
      "[50/100] Train loss: 0.4943 acc: 97.78 - Test loss: 0.5181 acc: 93.33\n",
      "[51/100] Train loss: 0.4804 acc: 97.78 - Test loss: 0.5067 acc: 95.00\n",
      "[52/100] Train loss: 0.4677 acc: 97.78 - Test loss: 0.4968 acc: 93.33\n",
      "[53/100] Train loss: 0.4558 acc: 97.78 - Test loss: 0.4884 acc: 95.00\n",
      "[54/100] Train loss: 0.4445 acc: 96.67 - Test loss: 0.4811 acc: 91.67\n",
      "[55/100] Train loss: 0.4340 acc: 96.67 - Test loss: 0.4745 acc: 90.00\n",
      "[56/100] Train loss: 0.4240 acc: 96.67 - Test loss: 0.4685 acc: 88.33\n",
      "[57/100] Train loss: 0.4147 acc: 96.67 - Test loss: 0.4626 acc: 88.33\n",
      "[58/100] Train loss: 0.4059 acc: 96.67 - Test loss: 0.4567 acc: 88.33\n",
      "[59/100] Train loss: 0.3977 acc: 96.67 - Test loss: 0.4505 acc: 88.33\n",
      "[60/100] Train loss: 0.3900 acc: 96.67 - Test loss: 0.4438 acc: 88.33\n",
      "[61/100] Train loss: 0.3827 acc: 96.67 - Test loss: 0.4369 acc: 88.33\n",
      "[62/100] Train loss: 0.3758 acc: 96.67 - Test loss: 0.4298 acc: 88.33\n",
      "[63/100] Train loss: 0.3692 acc: 96.67 - Test loss: 0.4227 acc: 90.00\n",
      "[64/100] Train loss: 0.3628 acc: 96.67 - Test loss: 0.4156 acc: 90.00\n",
      "[65/100] Train loss: 0.3567 acc: 96.67 - Test loss: 0.4088 acc: 91.67\n",
      "[66/100] Train loss: 0.3509 acc: 96.67 - Test loss: 0.4025 acc: 95.00\n",
      "[67/100] Train loss: 0.3452 acc: 96.67 - Test loss: 0.3967 acc: 96.67\n",
      "[68/100] Train loss: 0.3396 acc: 96.67 - Test loss: 0.3914 acc: 96.67\n",
      "[69/100] Train loss: 0.3342 acc: 96.67 - Test loss: 0.3868 acc: 96.67\n",
      "[70/100] Train loss: 0.3288 acc: 96.67 - Test loss: 0.3827 acc: 96.67\n",
      "[71/100] Train loss: 0.3236 acc: 96.67 - Test loss: 0.3789 acc: 96.67\n",
      "[72/100] Train loss: 0.3184 acc: 96.67 - Test loss: 0.3753 acc: 93.33\n",
      "[73/100] Train loss: 0.3134 acc: 96.67 - Test loss: 0.3717 acc: 91.67\n",
      "[74/100] Train loss: 0.3084 acc: 96.67 - Test loss: 0.3679 acc: 91.67\n",
      "[75/100] Train loss: 0.3035 acc: 96.67 - Test loss: 0.3639 acc: 91.67\n",
      "[76/100] Train loss: 0.2987 acc: 96.67 - Test loss: 0.3596 acc: 91.67\n",
      "[77/100] Train loss: 0.2940 acc: 96.67 - Test loss: 0.3550 acc: 91.67\n",
      "[78/100] Train loss: 0.2893 acc: 96.67 - Test loss: 0.3503 acc: 93.33\n",
      "[79/100] Train loss: 0.2847 acc: 96.67 - Test loss: 0.3457 acc: 93.33\n",
      "[80/100] Train loss: 0.2801 acc: 96.67 - Test loss: 0.3410 acc: 95.00\n",
      "[81/100] Train loss: 0.2757 acc: 96.67 - Test loss: 0.3365 acc: 96.67\n",
      "[82/100] Train loss: 0.2714 acc: 97.78 - Test loss: 0.3323 acc: 96.67\n",
      "[83/100] Train loss: 0.2671 acc: 97.78 - Test loss: 0.3284 acc: 96.67\n",
      "[84/100] Train loss: 0.2630 acc: 97.78 - Test loss: 0.3248 acc: 96.67\n",
      "[85/100] Train loss: 0.2589 acc: 97.78 - Test loss: 0.3214 acc: 96.67\n",
      "[86/100] Train loss: 0.2549 acc: 97.78 - Test loss: 0.3182 acc: 96.67\n",
      "[87/100] Train loss: 0.2510 acc: 97.78 - Test loss: 0.3148 acc: 96.67\n",
      "[88/100] Train loss: 0.2472 acc: 97.78 - Test loss: 0.3114 acc: 96.67\n",
      "[89/100] Train loss: 0.2434 acc: 97.78 - Test loss: 0.3078 acc: 96.67\n",
      "[90/100] Train loss: 0.2398 acc: 97.78 - Test loss: 0.3042 acc: 96.67\n",
      "[91/100] Train loss: 0.2361 acc: 97.78 - Test loss: 0.3005 acc: 96.67\n",
      "[92/100] Train loss: 0.2326 acc: 97.78 - Test loss: 0.2970 acc: 96.67\n",
      "[93/100] Train loss: 0.2292 acc: 97.78 - Test loss: 0.2937 acc: 96.67\n",
      "[94/100] Train loss: 0.2258 acc: 97.78 - Test loss: 0.2905 acc: 96.67\n",
      "[95/100] Train loss: 0.2224 acc: 97.78 - Test loss: 0.2876 acc: 96.67\n",
      "[96/100] Train loss: 0.2192 acc: 97.78 - Test loss: 0.2848 acc: 96.67\n",
      "[97/100] Train loss: 0.2160 acc: 97.78 - Test loss: 0.2820 acc: 96.67\n",
      "[98/100] Train loss: 0.2129 acc: 97.78 - Test loss: 0.2793 acc: 96.67\n",
      "[99/100] Train loss: 0.2098 acc: 97.78 - Test loss: 0.2766 acc: 96.67\n"
     ]
    }
   ],
   "source": [
    "seed = 4096\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "            \n",
    "max_epochs = 100\n",
    "for epoch in range(max_epochs):\n",
    "    tr_loss, tr_acc = train()\n",
    "    eva_loss, eva_acc = evaluate()\n",
    "    print(f'[{epoch}/{max_epochs}] Train loss: {tr_loss:.4f} acc: {tr_acc*100:.2f} - Test loss: {eva_loss:.4f} acc: {eva_acc*100:.2f}')\n",
    "    \n",
    "# [0/100] Train loss: 1.3462 acc: 27.78 - Test loss: 1.2278 acc: 41.67    \n",
    "# [99/100] Train loss: 0.2368 acc: 97.78 - Test loss: 0.2155 acc: 96.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Initial Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0986122886681098"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expect_loss = np.log(3)\n",
    "expect_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delving into Loss Functions for Classification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the toy example from Lecture 3 - Loss Functions and Optimization from Stanford University on YouTube  \n",
    "Link: https://youtu.be/h7iBpEHGVNc?t=502\n",
    "\n",
    "\n",
    "- Suppose: 3 training examples within 3 classes\n",
    "- 1 cat, 1 car, 1 frog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Classification Hinge loss\n",
    "Hinge loss function for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.FloatTensor([\n",
    "        [3.2, 5.1, -1.7],\n",
    "        [1.3, 4.9, 2],\n",
    "        [2.2, 2.5, -3.1],\n",
    "])\n",
    "y = torch.LongTensor([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9667, 0.0000, 4.3000])\n",
      "tensor(1.7556)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MultiMarginLoss(p=1, margin=1.0, reduction='none')\n",
    "loss = loss_fn(score, y)\n",
    "print(loss)\n",
    "\n",
    "loss_fn = nn.MultiMarginLoss(p=1, margin=1.0)\n",
    "loss = loss_fn(score, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.2000],\n",
      "        [ 4.9000],\n",
      "        [-3.1000]]) \n",
      "\n",
      "tensor([[ 0.0000,  2.9000, -3.9000],\n",
      "        [-2.6000,  0.0000, -1.9000],\n",
      "        [ 6.3000,  6.6000,  0.0000]]) \n",
      "\n",
      "tensor([ 2.9000,  0.0000, 12.9000]) \n",
      "\n",
      "tensor(1.7556)\n"
     ]
    }
   ],
   "source": [
    "s_diag = torch.diag(score).unsqueeze(1)\n",
    "print(s_diag, '\\n')\n",
    "\n",
    "s_y = torch.mm(s_diag, torch.ones(1,3))\n",
    "margin = score - s_y + 1\n",
    "margin = margin - torch.eye(3)\n",
    "print(margin, '\\n')\n",
    "\n",
    "z = torch.zeros(3, 3)\n",
    "margin = torch.max(margin, z)\n",
    "print(margin.sum(dim=1), '\\n')\n",
    "\n",
    "loss = margin.sum() / 9\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1., -1.],\n",
      "        [-1.,  1., -1.],\n",
      "        [-1., -1.,  1.]]) \n",
      "\n",
      "tensor([[ 1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
      "        [-1.0000e+10,  1.0000e+10, -1.0000e+10],\n",
      "        [-1.0000e+10, -1.0000e+10,  1.0000e+10]]) \n",
      "\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# min\n",
    "y_mat = -torch.ones(3, 3) + 2*torch.eye(3)\n",
    "print(y_mat, '\\n')\n",
    "\n",
    "x = 1e10 * y_mat\n",
    "print(x, '\\n')\n",
    "\n",
    "print(loss_fn(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0000e+10,  1.0000e+10,  1.0000e+10],\n",
      "        [ 1.0000e+10, -1.0000e+10,  1.0000e+10],\n",
      "        [ 1.0000e+10,  1.0000e+10, -1.0000e+10]]) \n",
      "\n",
      "tensor(1.3333e+10)\n"
     ]
    }
   ],
   "source": [
    "x = -1e10 * y_mat\n",
    "print(x, '\\n')\n",
    "\n",
    "print(loss_fn(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class multi-classification hinge loss\n",
    "Use this method when a train example can be signed with multiple labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.FloatTensor([\n",
    "        [3.2, 5.1, -1.7],\n",
    "        [1.3, 4.9, 2],\n",
    "        [2.2, 2.5, -3.1],\n",
    "])\n",
    "y = torch.LongTensor([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [1, 1, 1],\n",
      "        [2, 2, 2]]) \n",
      "\n",
      "tensor(5.2667)\n"
     ]
    }
   ],
   "source": [
    "y_multi_hinge = torch.LongTensor(range(3)).unsqueeze(dim=1).mm(torch.ones(1, 3, dtype=torch.long))\n",
    "print(y_multi_hinge, '\\n')\n",
    "\n",
    "loss_fn = nn.MultiLabelMarginLoss()\n",
    "loss = loss_fn(score, y_multi_hinge)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.2000,  3.2000,  3.2000],\n",
      "        [ 4.9000,  4.9000,  4.9000],\n",
      "        [-3.1000, -3.1000, -3.1000]]) \n",
      "\n",
      "tensor([[ 0.0000,  2.9000, -3.9000],\n",
      "        [-2.6000,  0.0000, -1.9000],\n",
      "        [ 6.3000,  6.6000,  0.0000]]) \n",
      "\n",
      "tensor([ 2.9000,  0.0000, 12.9000]) \n",
      "\n",
      "tensor(5.2667)\n"
     ]
    }
   ],
   "source": [
    "s_y = torch.mm(torch.diag(score).unsqueeze(1), torch.ones(1,3))\n",
    "print(s_y, '\\n')\n",
    "\n",
    "s_y = torch.mm(s_diag, torch.ones(1,3))\n",
    "margin = score - s_y + 1\n",
    "margin = margin - torch.eye(3)\n",
    "print(margin, '\\n')\n",
    "\n",
    "z = torch.zeros(3, 3)\n",
    "margin = torch.max(margin, z)\n",
    "print(margin.sum(dim=1), '\\n')\n",
    "\n",
    "loss = margin.sum() / 3\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Log Likelihood Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.FloatTensor([\n",
    "        [3.2, 5.1, -1.7],\n",
    "        [1.3, 4.9, 2],\n",
    "        [2.2, 2.5, -3.1],\n",
    "])\n",
    "y = torch.LongTensor([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0404, -0.1404, -6.9404],\n",
      "        [-3.6791, -0.0791, -2.9791],\n",
      "        [-0.8565, -0.5565, -6.1565]]) \n",
      "\n",
      "tensor(2.7587)\n"
     ]
    }
   ],
   "source": [
    "s = F.log_softmax(score, dim=1)\n",
    "print(s, '\\n')\n",
    "loss_fn = nn.NLLLoss()\n",
    "loss = loss_fn(s, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1300, 0.8690, 0.0010],\n",
      "        [0.0252, 0.9239, 0.0508],\n",
      "        [0.4247, 0.5732, 0.0021]]) \n",
      "\n",
      "tensor([[2.0404, 0.1404, 6.9404],\n",
      "        [3.6791, 0.0791, 2.9791],\n",
      "        [0.8565, 0.5565, 6.1565]]) \n",
      "\n",
      "tensor(2.7587)\n"
     ]
    }
   ],
   "source": [
    "x = F.softmax(score, dim=1)\n",
    "print(x, '\\n')\n",
    "x = -torch.log(x)\n",
    "print(x, '\\n')\n",
    "loss = (x[0][0] + x[1][1] + x[2][2]) / 3\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss\n",
    "Combines `LogSoftmax` and `NLLoss` into a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7587)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(score, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Cross Entropy Loss\n",
    "Using this method when the last layer is `Sigmoid` function and labels are using **one-hot encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9608, 0.9939, 0.1545],\n",
      "        [0.7858, 0.9926, 0.8808],\n",
      "        [0.9002, 0.9241, 0.0431]]) \n",
      "\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]]) \n",
      "\n",
      "tensor(1.8908)\n"
     ]
    }
   ],
   "source": [
    "x = torch.sigmoid(score)\n",
    "print(x, '\\n')\n",
    "# Binary Cross Entropy Loss\n",
    "y_oh = torch.eye(3)\n",
    "print(y_oh, '\\n')\n",
    "loss_fn = nn.BCELoss()\n",
    "loss = loss_fn(x, y_oh)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8908)\n"
     ]
    }
   ],
   "source": [
    "loss = -(y_oh*torch.log(x) + (1-y_oh)*torch.log(1-x))\n",
    "loss = loss.mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Cross Entropy Loss with Logits\n",
    "Combine the `Sigmoid` layer and the `BCELoss` into one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8908)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss = loss_fn(score, y_oh)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Margin Loss\n",
    "- It's similar to hinge loss but with smooth curve.\n",
    "- Adventage: Differentiable!\n",
    "- y in {-1, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1., -1.],\n",
      "        [-1.,  1., -1.],\n",
      "        [-1., -1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "score = torch.FloatTensor([\n",
    "        [3.2, 5.1, -1.7],\n",
    "        [1.3, 4.9, 2],\n",
    "        [2.2, 2.5, -3.1],\n",
    "])\n",
    "y = -torch.ones(3, 3) + 2*torch.eye(3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8908)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.SoftMarginLoss()\n",
    "loss = loss_fn(score, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0400, 5.1061, 0.1678],\n",
       "        [1.5410, 0.0074, 2.1269],\n",
       "        [2.3051, 2.5789, 3.1441]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(1 + torch.exp(-y * score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8908)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(1 + torch.exp(-y * score)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
      "        [-1.0000e+10,  1.0000e+10, -1.0000e+10],\n",
      "        [-1.0000e+10, -1.0000e+10,  1.0000e+10]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min\n",
    "x = 1e10 * y\n",
    "print(x, '\\n')\n",
    "loss_fn(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0000e+10,  1.0000e+10,  1.0000e+10],\n",
      "        [ 1.0000e+10, -1.0000e+10,  1.0000e+10],\n",
      "        [ 1.0000e+10,  1.0000e+10, -1.0000e+10]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(inf)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max\n",
    "x = -1e10 * y\n",
    "print(x, '\\n')\n",
    "loss_fn(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Label Soft Margin Loss\n",
    "\n",
    "- Multi-label one-versus-all\n",
    "- y in {0, 1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "score = torch.FloatTensor([\n",
    "        [3.2, 5.1, -1.7],\n",
    "        [1.3, 4.9, 2],\n",
    "        [2.2, 2.5, -3.1],\n",
    "])\n",
    "y = torch.eye(3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8908)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MultiLabelSoftMarginLoss()\n",
    "loss = loss_fn(score, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+10, -1.0000e+10, -1.0000e+10],\n",
      "        [-1.0000e+10,  1.0000e+10, -1.0000e+10],\n",
      "        [-1.0000e+10, -1.0000e+10,  1.0000e+10]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min\n",
    "x = 1e10 * (-torch.ones(3) + 2*torch.eye(3))\n",
    "print(x, '\\n')\n",
    "loss_fn(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000e+10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max\n",
    "x = -1e10 * (-torch.ones(3) + 2*torch.eye(3))\n",
    "loss_fn(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python36964bitvenvvenv794a3f6500e74251b078ca195c3ad1e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
